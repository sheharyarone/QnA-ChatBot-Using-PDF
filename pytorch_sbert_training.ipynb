{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24cc65c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ddfa131",
   "metadata": {},
   "outputs": [],
   "source": [
    "snli = datasets.load_dataset('snli',split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "537c80e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['premise', 'hypothesis', 'label'],\n",
       "    num_rows: 550152\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "610dbe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli = datasets.load_dataset(\"glue\",\"mnli\",split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e296ba1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "    num_rows: 392702\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8b12d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli = mnli.remove_columns([\"idx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bd686b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['premise', 'hypothesis', 'label'],\n",
       "    num_rows: 392702\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "726d35c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "snli = snli.cast(mnli.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "333c98c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.concatenate_datasets([snli,mnli])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf660ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Shuffle the dataset\n",
    "# dataset = dataset.shuffle(seed=42)\n",
    "\n",
    "# # Calculate the number of rows to keep (half of the original dataset)\n",
    "# num_rows_to_keep = len(dataset) // 2\n",
    "\n",
    "# # Select the first half of the shuffled dataset\n",
    "# dataset = dataset.select(list(range(num_rows_to_keep)))\n",
    "\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64da0620",
   "metadata": {},
   "outputs": [],
   "source": [
    "del snli, mnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0dfbeaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer,BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c08a641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "942069\n",
      "['label', 'premise_input_ids', 'premise_attention_mask', 'hypothesis_input_ids', 'hypothesis_attention_mask']\n"
     ]
    }
   ],
   "source": [
    "all_cols = ['label']\n",
    "dataset = dataset.filter(\n",
    "    lambda x:False if x['label']==-1 else True\n",
    ")\n",
    "print(len(dataset))\n",
    "for part in [\"premise\",\"hypothesis\"]:\n",
    "    dataset = dataset.map(\n",
    "        lambda x:tokenizer(\n",
    "            x[part],max_length=128,padding=\"max_length\",\n",
    "            truncation=True\n",
    "    ),batched=True\n",
    "    )\n",
    "    for col in [\"input_ids\",\"attention_mask\"]:\n",
    "        dataset=dataset.rename_column(\n",
    "            col,part+'_'+col  \n",
    "        )\n",
    "        all_cols.append(part+'_'+col)\n",
    "print(all_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cd11d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_format(type=\"torch\",columns = all_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66a84bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "batch_size = 16\n",
    "loader = torch.utils.data.DataLoader(dataset,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f1bea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pool(token_embeds,attention_mask):\n",
    "    in_mask = attention_mask.unsqueeze(-1).expand(\n",
    "        token_embeds.size()\n",
    "    ).float()\n",
    "    pool = torch.sum(token_embeds*in_mask,1)/torch.clamp(\n",
    "        in_mask.sum(1),min=1e-9\n",
    "    )\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebb10afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moved to cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "print(f\"moved to {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fec40925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define the layers to be used in classification\n",
    "ffnn = torch.nn.Linear(768*3,3)\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "#Move layers to device\n",
    "ffnn.to(device)\n",
    "loss_func.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87cf91ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc16690a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "from transformers import AdamW\n",
    "\n",
    "#Initialize Adam optimizer \n",
    "optim = AdamW(model.parameters(),lr = 1e-5)\n",
    "\n",
    "epochs = 1\n",
    "#setup warmup for first -10% steps\n",
    "total_steps = int(len(dataset)/batch_size)\n",
    "warmup_steps = int(0.1*total_steps*epochs)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optim,num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps-warmup_steps  \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc92e8c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|                                                        | 22/58880 [01:27<64:42:36,  3.96s/it, loss=1.09]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# update the TDQM progress bar\u001b[39;00m\n\u001b[0;32m     42\u001b[0m loop\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m loop\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 1 epoch should be enough, increase if wanted\n",
    "for epoch in range(1):\n",
    "    model.train()  # make sure model is in training mode\n",
    "    # initialize the dataloader loop with tqdm (tqdm == progress bar)\n",
    "    loop = tqdm(loader, leave=True)\n",
    "    for batch in loop:\n",
    "        # zero all gradients on each new step\n",
    "        optim.zero_grad()\n",
    "        # prepare batches and more all to the active device\n",
    "        inputs_ids_a = batch['premise_input_ids'].to(device)\n",
    "        inputs_ids_b = batch['hypothesis_input_ids'].to(device)\n",
    "        attention_a = batch['premise_attention_mask'].to(device)\n",
    "        attention_b = batch['hypothesis_attention_mask'].to(device)\n",
    "        label = batch['label'].to(device)\n",
    "        # extract token embeddings from BERT\n",
    "        u = model(\n",
    "            inputs_ids_a, attention_mask=attention_a\n",
    "        )[0]  # all token embeddings A\n",
    "        v = model(\n",
    "            inputs_ids_b, attention_mask=attention_b\n",
    "        )[0]  # all token embeddings B\n",
    "        # get the mean pooled vectors\n",
    "        u = mean_pool(u, attention_a)\n",
    "        v = mean_pool(v, attention_b)\n",
    "        # build the |u-v| tensor\n",
    "        uv = torch.sub(u, v)\n",
    "        uv_abs = torch.abs(uv)\n",
    "        # concatenate u, v, |u-v|\n",
    "        x = torch.cat([u, v, uv_abs], dim=-1)\n",
    "        # process concatenated tensor through FFNN\n",
    "        x = ffnn(x)\n",
    "        # calculate the 'softmax-loss' between predicted and true label\n",
    "        loss = loss_func(x, label)\n",
    "        # using loss, calculate gradients and then optimize\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        # update learning rate scheduler\n",
    "        scheduler.step()\n",
    "        # update the TDQM progress bar\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00126d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "model_path = './sbert_test_c'\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    os.mkdir(model_path)\n",
    "model.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9c3d115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moved to cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel,BertTokenizer\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "print(f\"moved to {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7124639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertModel.from_pretrained(\"./sbert_test_c\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29aa1e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_to_hub(\n",
    "#     \"distilroberta-base-sentence-transformer\", \n",
    "#     organization= \"Shayaan69\"\n",
    "#     train_datasets=[\"embedding-data/QQP_triplets\"],\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0fba91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6f08c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
